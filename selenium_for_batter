from selenium import webdriver
from selenium.webdriver.chrome.options import Options as options
from bs4 import BeautifulSoup
from time import sleep
import datetime
import pandas as pd

options = options()
prefs = {
    'profile.default_content_setting_values' :
        {
        'notifications' : 2
         }
}
options.add_experimental_option('prefs',prefs)
options.add_argument("--headless")
headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36'}
year = 2010 #input('請輸入年份')
page=1
url = 'https://www.baseball-reference.com/boxes/HOU/HOU201910300.shtml'
driver = webdriver.Chrome("./chromedriver.exe",options=options)
#driver.implicitly_wait(10)
html = driver.get(url)
# sleep(5)
html_data = driver.page_source
#soup = BeautifulSoup(html,'html.parser')
tables = pd.read_html(html_data)
print(tables[9])


a = tables[9]
b = a['Batting']
c = ','.join(str(i) for i in b).split(',')
# print(len(c))
Batting = []
for i in c:
    x = i.split(' ')
    y = len(x)
    if y == 3 :
        a = i.split(' ')
        # print(a[2][:2])
        if a[2][:2] == 'P' :
            continue
        elif a[2][:2] == 'PH':
            continue
        else:
            batter = a[0] + ' ' + a[1]
            Batting += [batter]
    else:
        pass
print(Batting)



tables[9].to_csv('tt.csv',encoding='utf-8-sig')

driver.close()
